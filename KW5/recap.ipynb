{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autumn is a season known for its colorful leaves and cooler temperatures. Many people enjoy walks in the woods to admire the vibrant colors of nature. It is also the time of harvest, with an abundance of fruits and vegetables. Pumpkins, apples, and grapes are typical autumn fruits used in many recipes. Autumn also brings holidays like Halloween and Thanksgiving, celebrated by many families. Overall, autumn is a time of change and preparation for winter.\n"
     ]
    }
   ],
   "source": [
    "text = \"Autumn is a season known for its colorful leaves and cooler temperatures. Many people enjoy walks in the woods to admire the vibrant colors of nature. It is also the time of harvest, with an abundance of fruits and vegetables. Pumpkins, apples, and grapes are typical autumn fruits used in many recipes. Autumn also brings holidays like Halloween and Thanksgiving, celebrated by many families. Overall, autumn is a time of change and preparation for winter.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "u\n",
      "t\n",
      "u\n",
      "m\n",
      "n\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "s\n",
      "e\n",
      "a\n",
      "s\n",
      "o\n",
      "n\n",
      " \n",
      "k\n",
      "n\n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "o\n",
      "r\n",
      "f\n",
      "u\n",
      "l\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "v\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "c\n",
      "o\n",
      "o\n",
      "l\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "e\n",
      "m\n",
      "p\n",
      "e\n",
      "r\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "M\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "p\n",
      "e\n",
      "o\n",
      "p\n",
      "l\n",
      "e\n",
      " \n",
      "e\n",
      "n\n",
      "j\n",
      "o\n",
      "y\n",
      " \n",
      "w\n",
      "a\n",
      "l\n",
      "k\n",
      "s\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "o\n",
      "d\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "a\n",
      "d\n",
      "m\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "v\n",
      "i\n",
      "b\n",
      "r\n",
      "a\n",
      "n\n",
      "t\n",
      " \n",
      "c\n",
      "o\n",
      "l\n",
      "o\n",
      "r\n",
      "s\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "n\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      ".\n",
      " \n",
      "I\n",
      "t\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "h\n",
      "a\n",
      "r\n",
      "v\n",
      "e\n",
      "s\n",
      "t\n",
      ",\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "a\n",
      "n\n",
      " \n",
      "a\n",
      "b\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "f\n",
      "r\n",
      "u\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "v\n",
      "e\n",
      "g\n",
      "e\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "P\n",
      "u\n",
      "m\n",
      "p\n",
      "k\n",
      "i\n",
      "n\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "e\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "g\n",
      "r\n",
      "a\n",
      "p\n",
      "e\n",
      "s\n",
      " \n",
      "a\n",
      "r\n",
      "e\n",
      " \n",
      "t\n",
      "y\n",
      "p\n",
      "i\n",
      "c\n",
      "a\n",
      "l\n",
      " \n",
      "a\n",
      "u\n",
      "t\n",
      "u\n",
      "m\n",
      "n\n",
      " \n",
      "f\n",
      "r\n",
      "u\n",
      "i\n",
      "t\n",
      "s\n",
      " \n",
      "u\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "c\n",
      "i\n",
      "p\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "A\n",
      "u\n",
      "t\n",
      "u\n",
      "m\n",
      "n\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      "s\n",
      " \n",
      "h\n",
      "o\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      "y\n",
      "s\n",
      " \n",
      "l\n",
      "i\n",
      "k\n",
      "e\n",
      " \n",
      "H\n",
      "a\n",
      "l\n",
      "l\n",
      "o\n",
      "w\n",
      "e\n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "T\n",
      "h\n",
      "a\n",
      "n\n",
      "k\n",
      "s\n",
      "g\n",
      "i\n",
      "v\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "c\n",
      "e\n",
      "l\n",
      "e\n",
      "b\n",
      "r\n",
      "a\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "y\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "l\n",
      "i\n",
      "e\n",
      "s\n",
      ".\n",
      " \n",
      "O\n",
      "v\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "l\n",
      ",\n",
      " \n",
      "a\n",
      "u\n",
      "t\n",
      "u\n",
      "m\n",
      "n\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "a\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "c\n",
      "h\n",
      "a\n",
      "n\n",
      "g\n",
      "e\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "p\n",
      "r\n",
      "e\n",
      "p\n",
      "a\n",
      "r\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      " \n",
      "f\n",
      "o\n",
      "r\n",
      " \n",
      "w\n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      "r\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for letter in text:\n",
    "    print(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Autumn',\n",
       " 'is',\n",
       " 'a',\n",
       " 'season',\n",
       " 'known',\n",
       " 'for',\n",
       " 'its',\n",
       " 'colorful',\n",
       " 'leaves',\n",
       " 'and',\n",
       " 'cooler',\n",
       " 'temperatures',\n",
       " '.',\n",
       " 'Many',\n",
       " 'people',\n",
       " 'enjoy',\n",
       " 'walks',\n",
       " 'in',\n",
       " 'the',\n",
       " 'woods',\n",
       " 'to',\n",
       " 'admire',\n",
       " 'the',\n",
       " 'vibrant',\n",
       " 'colors',\n",
       " 'of',\n",
       " 'nature',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'also',\n",
       " 'the',\n",
       " 'time',\n",
       " 'of',\n",
       " 'harvest',\n",
       " ',',\n",
       " 'with',\n",
       " 'an',\n",
       " 'abundance',\n",
       " 'of',\n",
       " 'fruits',\n",
       " 'and',\n",
       " 'vegetables',\n",
       " '.',\n",
       " 'Pumpkins',\n",
       " ',',\n",
       " 'apples',\n",
       " ',',\n",
       " 'and',\n",
       " 'grapes',\n",
       " 'are',\n",
       " 'typical',\n",
       " 'autumn',\n",
       " 'fruits',\n",
       " 'used',\n",
       " 'in',\n",
       " 'many',\n",
       " 'recipes',\n",
       " '.',\n",
       " 'Autumn',\n",
       " 'also',\n",
       " 'brings',\n",
       " 'holidays',\n",
       " 'like',\n",
       " 'Halloween',\n",
       " 'and',\n",
       " 'Thanksgiving',\n",
       " ',',\n",
       " 'celebrated',\n",
       " 'by',\n",
       " 'many',\n",
       " 'families',\n",
       " '.',\n",
       " 'Overall',\n",
       " ',',\n",
       " 'autumn',\n",
       " 'is',\n",
       " 'a',\n",
       " 'time',\n",
       " 'of',\n",
       " 'change',\n",
       " 'and',\n",
       " 'preparation',\n",
       " 'for',\n",
       " 'winter',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Autumn', 'is', 'a', 'season', 'known', 'for', 'it', 'colorful', 'leaf', 'and', 'cooler', 'temperature', '.', 'Many', 'people', 'enjoy', 'walk', 'in', 'the', 'wood', 'to', 'admire', 'the', 'vibrant', 'color', 'of', 'nature', '.', 'It', 'is', 'also', 'the', 'time', 'of', 'harvest', ',', 'with', 'an', 'abundance', 'of', 'fruit', 'and', 'vegetable', '.', 'Pumpkins', ',', 'apple', ',', 'and', 'grape', 'are', 'typical', 'autumn', 'fruit', 'used', 'in', 'many', 'recipe', '.', 'Autumn', 'also', 'brings', 'holiday', 'like', 'Halloween', 'and', 'Thanksgiving', ',', 'celebrated', 'by', 'many', 'family', '.', 'Overall', ',', 'autumn', 'is', 'a', 'time', 'of', 'change', 'and', 'preparation', 'for', 'winter', '.']\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokes = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(lemmatized_tokes)\n",
    "print(len(lemmatized_tokes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "lowered = [token.lower() for token in lemmatized_tokes]\n",
    "len(lowered)\n",
    "print(len(lowered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['autumn', 'is', 'a', 'season', 'known', 'for', 'it', 'colorful', 'leaf', 'and', 'cooler', 'temperature', 'many', 'people', 'enjoy', 'walk', 'in', 'the', 'wood', 'to', 'admire', 'the', 'vibrant', 'color', 'of', 'nature', 'it', 'is', 'also', 'the', 'time', 'of', 'harvest', 'with', 'an', 'abundance', 'of', 'fruit', 'and', 'vegetable', 'pumpkins', 'apple', 'and', 'grape', 'are', 'typical', 'autumn', 'fruit', 'used', 'in', 'many', 'recipe', 'autumn', 'also', 'brings', 'holiday', 'like', 'halloween', 'and', 'thanksgiving', 'celebrated', 'by', 'many', 'family', 'overall', 'autumn', 'is', 'a', 'time', 'of', 'change', 'and', 'preparation', 'for', 'winter']\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "without_punctuation = [token for token in lowered if token not in string.punctuation]\n",
    "print(without_punctuation)\n",
    "print(len(without_punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['autumn', 'season', 'known', 'colorful', 'leaf', 'cooler', 'temperature', 'many', 'people', 'enjoy', 'walk', 'wood', 'admire', 'vibrant', 'color', 'nature', 'also', 'time', 'harvest', 'abundance', 'fruit', 'vegetable', 'pumpkins', 'apple', 'grape', 'typical', 'autumn', 'fruit', 'used', 'many', 'recipe', 'autumn', 'also', 'brings', 'holiday', 'like', 'halloween', 'thanksgiving', 'celebrated', 'many', 'family', 'overall', 'autumn', 'time', 'change', 'preparation', 'winter']\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "without_stopwords = [\n",
    "    token for token in without_punctuation if token not in stopwords.words(\"english\")]\n",
    "print(without_stopwords)\n",
    "print(len(without_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing stopwords 52\n",
      "after removing stopwords 39\n"
     ]
    }
   ],
   "source": [
    "print(\"before removing stopwords\", len(set(without_punctuation)))\n",
    "print(\"after removing stopwords\", len(set(without_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autumn',\n",
       " 'season',\n",
       " 'known',\n",
       " 'colorful',\n",
       " 'leaf',\n",
       " 'cooler',\n",
       " 'temperature',\n",
       " 'many',\n",
       " 'people',\n",
       " 'enjoy',\n",
       " 'walk',\n",
       " 'wood',\n",
       " 'admire',\n",
       " 'vibrant',\n",
       " 'color',\n",
       " 'nature',\n",
       " 'also',\n",
       " 'time',\n",
       " 'harvest',\n",
       " 'abundance',\n",
       " 'fruit',\n",
       " 'vegetable',\n",
       " 'pumpkins',\n",
       " 'apple',\n",
       " 'grape',\n",
       " 'typical',\n",
       " 'autumn',\n",
       " 'fruit',\n",
       " 'used',\n",
       " 'many',\n",
       " 'recipe',\n",
       " 'autumn',\n",
       " 'also',\n",
       " 'brings',\n",
       " 'holiday',\n",
       " 'like',\n",
       " 'halloween',\n",
       " 'thanksgiving',\n",
       " 'celebrated',\n",
       " 'many',\n",
       " 'family',\n",
       " 'overall',\n",
       " 'autumn',\n",
       " 'time',\n",
       " 'change',\n",
       " 'preparation',\n",
       " 'winter']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['autumn', 'season', 'known', 'color', 'leaf', 'cooler', 'temperatur', 'mani', 'peopl', 'enjoy', 'walk', 'wood', 'admir', 'vibrant', 'color', 'natur', 'also', 'time', 'harvest', 'abund', 'fruit', 'veget', 'pumpkin', 'appl', 'grape', 'typic', 'autumn', 'fruit', 'use', 'mani', 'recip', 'autumn', 'also', 'bring', 'holiday', 'like', 'halloween', 'thanksgiv', 'celebr', 'mani', 'famili', 'overal', 'autumn', 'time', 'chang', 'prepar', 'winter']\n",
      "47\n",
      "['autumn', 'season', 'known', 'colorful', 'leaf', 'cooler', 'temperature', 'many', 'people', 'enjoy', 'walk', 'wood', 'admire', 'vibrant', 'color', 'nature', 'also', 'time', 'harvest', 'abundance', 'fruit', 'vegetable', 'pumpkins', 'apple', 'grape', 'typical', 'autumn', 'fruit', 'used', 'many', 'recipe', 'autumn', 'also', 'brings', 'holiday', 'like', 'halloween', 'thanksgiving', 'celebrated', 'many', 'family', 'overall', 'autumn', 'time', 'change', 'preparation', 'winter']\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Eigentlich entweder lemmatisieren oder Stemming\n",
    "stemmed_tokens = [stemmer.stem(token) for token in without_stopwords]\n",
    "print(stemmed_tokens)\n",
    "print(len(stemmed_tokens))\n",
    "\n",
    "\n",
    "print(without_stopwords)\n",
    "print(len(without_stopwords))\n",
    "\n",
    "# Lemmatisieren beinhaltet mehr Details und wird meistens bessere Insights liefern\n",
    "# Steming ist eine Alternative für die Analyse von Text über ML Mehtoden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample_1 = \"I love the new features in the latest update! The app is much faster and more user-friendly now. Great job!\"\n",
    "text_sample_2 = \"The recent update is terrible. The app crashes frequently and the new interface is confusing. Very disappointed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.444, 'pos': 0.556, 'compound': 0.3612}\n",
      "{'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'compound': -0.3404}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentiment_score1 = sid.polarity_scores(\"I like this weather\")\n",
    "print(sentiment_score1)\n",
    "sentiment_score2 = sid.polarity_scores(\"I not like this weather!\")\n",
    "print(sentiment_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.408, 'pos': 0.592, 'compound': 0.4404}\n",
      "{'neg': 0.0, 'neu': 0.484, 'pos': 0.516, 'compound': 0.4927}\n"
     ]
    }
   ],
   "source": [
    "sentiment_score1 = sid.polarity_scores(\"This is good\")\n",
    "print(sentiment_score1)\n",
    "sentiment_score2 = sid.polarity_scores(\"This is very good\")\n",
    "print(sentiment_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.65, 'pos': 0.35, 'compound': 0.8792}\n",
      "{'neg': 0.375, 'neu': 0.625, 'pos': 0.0, 'compound': -0.8122}\n"
     ]
    }
   ],
   "source": [
    "sentiment_score1 = sid.polarity_scores(text_sample_1)\n",
    "print(sentiment_score1)\n",
    "sentiment_score2 = sid.polarity_scores(text_sample_2)\n",
    "print(sentiment_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.9)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([2, 1, 1, 3, 2, 4, 2, 2, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.572, 'pos': 0.428, 'compound': 0.4585}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(\"I do not hate this weather\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.09531666666666666)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(\"I do not hate this weather\")\n",
    "\n",
    "np.mean([sid.polarity_scores(token)['compound'] for token in tokens])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
