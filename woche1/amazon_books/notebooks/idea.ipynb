{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Überblick und Herangehensweise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspiration für Dateistruktur**\n",
    "https://gist.github.com/ericmjl/27e50331f24db3e8f957d1fe7bbbe510"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Teil 1: Das drum herum\n",
    "1. Ziel/ Scope der Analyse festlegen -> Beispiel: Was sind Faktoren für den Erfolg eines Buches bei Amazon\n",
    "1. Projektstruktur aufsetzen\n",
    "1. Daten beschaffen\n",
    "   \n",
    "#### Teil 2: Befähigen, mit den Daten zu arbeiten\n",
    "1. Wenn möglich, daten in Excel, Texteditor o. ä. ansehen\n",
    "    - Hilft, um Datenformat zu versehen\n",
    "    - Bei Bedarf schon einmal Filtern etc. (um ein Verständnis für die Daten zu erhalten)\n",
    "2. Daten einlesen\n",
    "3. Allgemeine Informationen untersuchen\n",
    "    - df.head() -> Spalten ansehen,\n",
    "    - df.info() -> Datentypen, anzahl Werte\n",
    "    - df.shape -> Dimension der Daten\n",
    "    - df.describe() -> Statisiken, Verteilung der Daten\n",
    "    - df.isna().sum() -> Missing Values\n",
    "    - df.duplicated() -> Doppelte Zeilen\n",
    "4. Daten verstehen -> Zieht sich über alle Punkte in Teil 2\n",
    "\n",
    "Am Ende von Teil 2 sollten wir ein Verständnis dafür haben, was für Daten uns vorliergen und wie diese ungefähr aussehen. Das kann durch Tabellen oder auch einfache Statisiken erreicht werden. In der Regel wird Schritt 4 eher in einem Draft/ eigenen Notebook hinterlegt. Charakter von 4. entspricht einem Schmierzettel.\n",
    "\n",
    "#### Teil 3: Daten aufbereiten & analysieren\n",
    "\n",
    "Aus Teil 2.4 werden Vermutungen zu Teil 1.1 enstehen. Diese werden im nachfolgenden Prozess Mittelpunkt unseres Vorgehens sein.\n",
    "\n",
    "1. Fragen entwickeln/ Hypothesen aufstellen\n",
    "    - Passend zu 1.1\n",
    "2. Data Cleaning -> Beispiel: Was muss ich anpassen, um den Durchschnittspreis je Autor später anzuzeigen\n",
    "   - Datentypen anpassen\n",
    "   - Duplikate behandeln\n",
    "   - Missing Values behandeln\n",
    "   - Spaltennamen anpassen, falls nicht gut benannt\n",
    "   - Strings bereinigen (Casing, Spacing, Delimeter)\n",
    "   - Ausreißer behandeln\n",
    "   - Subsets bilden\n",
    "3. Data Processing -> Noch nicht behandelt\n",
    "   - Skalierungen\n",
    "   - Kodierung von Spalten (One-hot, ...), Boolsche Masken\n",
    "4. Feature Engineering -> noch nicht behandelt\n",
    "    - Neue Spalten erstellen \n",
    "5. Relevante Features identifizieren -> Dieser Schritt steht oft im Wechselspiel mit 3.1 und 3.2\n",
    "    - Domänenwissen\n",
    "    - Korrelationen\n",
    "    - Lineare Zusammenhänge\n",
    "    - Statistische Zusammenhänge\n",
    "6. Frage aus 3.1 beantworten\n",
    "\n",
    "#### Teil 4: Modelle entwickeln -> Später\n",
    "\n",
    "#### Teil 5: Abschließende Analyse\n",
    "\n",
    "1. Code aus Teil 3 refactorn/ in neuem Notebook zusammenfassen\n",
    "2. Nach Bedarf Dashboard bauen\n",
    "\n",
    "\n",
    "#### Generelles\n",
    "- Daten und Ergebnisse regelmäßig hinterfragen\n",
    "- Lieber neue DataFrames erstellen, als sie zu überschreiben\n",
    "- Manchmal ist es einfacher, ein weiteres Notebook zu erstellen, als ein Notebook zu überfüllen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
